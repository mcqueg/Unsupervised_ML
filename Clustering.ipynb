{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with the Basic Sequential Clustering Algorithm\n",
    "\n",
    "#### Garrett McCue\n",
    "\n",
    "\n",
    "Goal of the assignment is to apply BSCA, testing 3 different values for both of the clustering hyperparameters, $\\alpha$ and $M$ , to the 1D and 2D projections of the [Stellar Classification Dataset](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17) from both PCA and LD techniques which was apart of the [Dimensionality Reduction assignment](https://nbviewer.org/github/mcqueg/Unsupervised_ML_Assignments/blob/main/Dimensionality_Reduction.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[1. What is Clustering?](#Clustering)</br>\n",
    "[2. BSCA Logic](#bsca)</br>\n",
    "[3. BSCA Code](#code)</br>\n",
    "[4. Load and Transform Data](#data)</br>\n",
    "[5. 1D Projections with BSCA](#1d) </br>\n",
    "[6. 2D Projections with BSCA](#2d) </br>\n",
    "[7. Clustering Analysis](#analsis) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is Clustering? <a class=\"anchor\" id=\"Clustering\"></a>\n",
    "\n",
    "Clustering is an unsupervised technique that aims to form groupings of data points without any class knowledge. This technique is not classification, because we want to discover groupings of data independent of their respective classes. Since this process is unsupervised it can be common to get results that have a different number of groupings in comparison with the amount of unique classes within the data. Determining what data point belong within each cluster and the number of cluster is based on a chosen distance measurement between data points and the clusters as well as a specified distance threshold and max cluster number. When implementing clustering techniques the high dimensionality of data can make the process difficult. Sometimes it might be necessary to perform dimensionality reduction techniques before the application of a clustering technique. It can also be tricky to find the correct number of clusters as well as choosing the distance threshold. When implementing clustering the threshold of distance ($\\alpha$) parameter and max number of clusters ($M$) parameter must be specified. You can initialize the first point as the first cluster and then loop through the rest of the points, or samples until the end. While iterating through the points the minimum distance between each sample point and the cluster(s) will be computed, and if it falls beyond the specified distance threshold and the current cluster total is less than $M$ then a new cluster can be formed from that point. If the minimum distance of a point with one of the clusters cluster falls below the distance threshold, then that point is then added to the cluster it is closest too. This process iterates through all samples adding each one to a cluster or creating a new cluster until all samples distances have been measured and grouped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## BSCA Logic <a class=\"anchor\" id=\"bsca\"></a>\n",
    "User defined parameters...\n",
    "$$\\alpha = \\text{distance threshold}$$\n",
    "$$ M  = \\text{maximum cluster count} $$\n",
    "</br >Initialize the cluster total $t$ as 1 and the first sample, $\\vec{X_i}$ as the first cluster, $C_1$\n",
    "$$ t = 1;\\quad \\text{where}\\; t = \\text{cluster total} $$\n",
    "$$\\vec{X_1} = C_1$$\n",
    "</br >For all samples, $\\vec{X_2}...\\vec{X_N}$, find the minimum distance to each cluster $d_{min}(\\vec{X_i}, C_j)$\n",
    "$$ d_{min}(\\vec{X_i}, C_j)\\;; \\quad i = 2,...,N $$\n",
    "</br >If the distance is beyond the threshold $\\alpha$, and the cluster total ($t$) is less than the threshold $M$ then create a new cluster from the data point and update the total cluster number.\n",
    "$$ IF \\quad d(\\vec{X_i}, C_j) > \\alpha \\quad AND\\quad t < M $$\n",
    "then, \n",
    "$$ t = t + 1 $$\n",
    "$$ C_t = \\vec{X_i} $$\n",
    "</br >If the distance is not beyond the threshold ($\\alpha$) then add that point to the corresponding cluster ($C_j$) with the smallest distance measure\n",
    "$$ IF \\quad d(\\vec{X_i}, C_j) < \\alpha $$\n",
    "then,\n",
    "$$ C_j = C_j \\cup \\vec{X_i} $$\n",
    "\n",
    "</br >Continue finding the minimum distances and assigning samples to the closest cluster or create a new cluster from samples until all samples have been assigned to a cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Transform Data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and data\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from dims_reduction import PCA, LDA\n",
    "\n",
    "# Load data\n",
    "DATA = 'data/star_classification.csv'\n",
    "stellar_df = pd.read_csv(DATA)\n",
    "labels_df = pd.DataFrame(stellar_df['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Projection of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D PCA shape: (100000, 1)\n",
      "2D PCA shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_pca = stellar_df.drop(columns='class')\n",
    " \n",
    "# 1D PCA\n",
    "# create the one dimensional data and set the column to be the 1st principal component\n",
    "pca_one_df = pd.DataFrame(PCA(X_pca, 1), columns=['PC1'])\n",
    "# join the classes back to the observations\n",
    "#pca_one_df = pd.concat([pca_one_df, labels_df], axis=1)\n",
    "\n",
    "# 2D PCA\n",
    "# create the one dimensional data and set the column to be the 1st principal component\n",
    "pca_two_df = pd.DataFrame(PCA(X_pca, 2), columns=['PC1', 'PC2'])\n",
    "# join the classes back to the observations\n",
    "#pca_two_df = pd.concat([pca_two_df, labels_df], axis=1)\n",
    "\n",
    "print(\"1D PCA shape: {}\\n2D PCA shape: {}\".format(pca_one_df.shape, pca_two_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Projection of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D LDA shape: (100000, 1)\n",
      "2D LDA shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# drop id fields\n",
    "columns = ['class','obj_ID', 'run_ID','rerun_ID', 'field_ID', 'spec_obj_ID', 'MJD', 'fiber_ID', 'cam_col', 'plate']\n",
    "X_lda = stellar_df.drop(columns=columns)\n",
    "labels = stellar_df['class']\n",
    "#1D LDA\n",
    "lda_one = LDA(data=X_lda, labels=labels, n=1)\n",
    "#2D LDA\n",
    "lda_two = LDA(data=X_lda, labels=labels, n=2)\n",
    "\n",
    "print(\"1D LDA shape: {}\\n2D LDA shape: {}\".format(lda_one.shape, lda_two.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "935f013ec3274d983f6cf9c6c8d3a038a9827a62579d2563240b276044aef7b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
