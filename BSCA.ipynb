{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with the Basic Sequential Clustering Algorithm\n",
    "\n",
    "#### Garrett McCue\n",
    "\n",
    "\n",
    "Goal of the assignment is to apply BSCA, testing 3 different values for both of the clustering hyperparameters, $\\alpha$ and $M$ , to the 1D and 2D projections of the [Stellar Classification Dataset](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17) from both PCA and LD techniques which was apart of the [Dimensionality Reduction assignment](https://nbviewer.org/github/mcqueg/Unsupervised_ML_Assignments/blob/main/Dimensionality_Reduction.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[1. What is Clustering?](#Clustering)\n",
    "\n",
    "[2. BSCA Logic](#bsca)\n",
    "\n",
    "[3. Load and Transform Data](#data)\n",
    "\n",
    "[4. BSCA Code](#code)\n",
    "\n",
    "[5. 1D Projections with BSCA](#1d)\n",
    "\n",
    "[6. 2D Projections with BSCA](#2d)\n",
    "\n",
    "[7. Clustering Analysis](#analysis)\n",
    "\n",
    "[8. Complete Code](#code2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is Clustering? <a class=\"anchor\" id=\"Clustering\"></a>\n",
    "![](https://devopedia.org/images/article/242/4320.1575221317.png)\n",
    "\n",
    "Clustering is an unsupervised technique that aims to form groupings of data points without any class knowledge. This technique is not classification, because we want to discover groupings of data independent of their respective classes. Since this process is unsupervised it can be common to get results that have a different number of groupings in comparison with the amount of unique classes within the data. Determining what data point belong within each cluster and the number of cluster is based on a chosen distance measurement between data points and the clusters as well as a specified distance threshold and max cluster number. When implementing clustering techniques the high dimensionality of data can make the process difficult. Sometimes it might be necessary to perform dimensionality reduction techniques before the application of a clustering technique. It can also be tricky to find the correct number of clusters as well as choosing the distance threshold. When implementing clustering the threshold of distance ($\\alpha$) parameter and max number of clusters ($M$) parameter must be specified. You can initialize the first point as the first cluster and then loop through the rest of the points, or samples until the end. While iterating through the points the minimum distance between each sample point and the cluster(s) will be computed, and if it falls beyond the specified distance threshold and the current cluster total is less than $M$ then a new cluster can be formed from that point. If the minimum distance of a point with one of the clusters cluster falls below the distance threshold, then that point is then added to the cluster it is closest too. This process iterates through all samples adding each one to a cluster or creating a new cluster until all samples distances have been measured and grouped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## BSCA Logic <a class=\"anchor\" id=\"bsca\"></a>\n",
    "User defined parameters...\n",
    "$$\\alpha = \\text{distance threshold}$$\n",
    "$$ M  = \\text{maximum cluster count} $$\n",
    "Initialize the cluster total $t$ as 1 and the first sample, $\\vec{X_i}$ as the first cluster, $C_1$\n",
    "$$ t = 1;\\quad \\text{where}\\; t = \\text{cluster total} $$\n",
    "$$\\vec{X_1} = C_1$$\n",
    "For all samples, $\\vec{X_2}...\\vec{X_N}$, find the minimum distance to each cluster $d_{min}(\\vec{X_i}, C_j)$\n",
    "$$ d_{min}(\\vec{X_i}, C_j)\\;; \\quad i = 2,...,N $$\n",
    "If the distance is beyond the threshold $\\alpha$, and the cluster total ($t$) is less than the threshold $M$ then create a new cluster from the data point and update the total cluster number.\n",
    "$$ IF \\quad d(\\vec{X_i}, C_j) > \\alpha \\quad AND\\quad t < M $$\n",
    "then, \n",
    "$$ t = t + 1 $$\n",
    "$$ C_t = \\vec{X_i} $$\n",
    "If the distance is not beyond the threshold ($\\alpha$) then add that point to the corresponding cluster ($C_j$) with the smallest distance measure\n",
    "$$ IF \\quad d(\\vec{X_i}, C_j) < \\alpha $$\n",
    "then,\n",
    "$$ C_j = C_j \\cup \\vec{X_i} $$\n",
    "\n",
    "Continue finding the minimum distances and assigning samples to the closest cluster or create a new cluster from samples until all samples have been assigned to a cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Transform Data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "from dims_reduction import PCA, LDA\n",
    "\n",
    "# Load data\n",
    "DATA = 'data/star_classification.csv'\n",
    "stellar_df = pd.read_csv(DATA)\n",
    "labels_df = pd.DataFrame(stellar_df['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Projection of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D PCA shape: (100000, 1)\n",
      "2D PCA shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_pca = stellar_df.drop(columns='class')\n",
    " \n",
    "# 1D PCA\n",
    "# create the one dimensional data and set the column to be the 1st principal component\n",
    "pca_one = pd.DataFrame(PCA(X_pca, 1), columns=['PC1'])\n",
    "# join the classes back to the observations\n",
    "#pca_one_df = pd.concat([pca_one_df, labels_df], axis=1)\n",
    "\n",
    "# 2D PCA\n",
    "# create the one dimensional data and set the column to be the 1st principal component\n",
    "pca_two = pd.DataFrame(PCA(X_pca, 2), columns=['PC1', 'PC2'])\n",
    "# join the classes back to the observations\n",
    "#pca_two_df = pd.concat([pca_two_df, labels_df], axis=1)\n",
    "\n",
    "print(\"1D PCA shape: {}\\n2D PCA shape: {}\".format(pca_one.shape, pca_two.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Projection of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D LDA shape: (100000, 1)\n",
      "2D LDA shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# drop id fields\n",
    "columns = ['class','obj_ID', 'run_ID','rerun_ID', 'field_ID', 'spec_obj_ID', 'MJD', 'fiber_ID', 'cam_col', 'plate']\n",
    "X_lda = stellar_df.drop(columns=columns)\n",
    "labels = stellar_df['class']\n",
    "#1D LDA\n",
    "lda_one = LDA(data=X_lda, labels=labels, n=1)\n",
    "#2D LDA\n",
    "lda_two = LDA(data=X_lda, labels=labels, n=2)\n",
    "\n",
    "print(\"1D LDA shape: {}\\n2D LDA shape: {}\".format(lda_one.shape, lda_two.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BSCA Code <a class=\"anchor\" id=\"code\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for calculating the distance from a point (row) to the passed cluster\n",
    "def clust_distance(X, cluster):\n",
    "    # 1D projection, distance calc\n",
    "    if len(X) == 1: # if there is one column..\n",
    "        distance = abs(X - np.mean(cluster))\n",
    "    # 2D projection\n",
    "    elif len(X) == 2: # 2 columns\n",
    "        cluster_means = np.mean(np.array(cluster), axis=0)\n",
    "        distance = np.sqrt((cluster_means[0] - X[0])**2 + (cluster_means[1] - X[1])**2)\n",
    "    else:\n",
    "        print(\"could not find distance to cluster\")\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSCA(data, m, alpha):\n",
    "    '''\n",
    "    Arguments: \n",
    "    data -> df of data to cluster, observations row wise\n",
    "    -> int, number of clusters to find within data\n",
    "      alpha -> int, distance threshold, \n",
    "            determines how far away a point can be before it must create a new cluster\n",
    "    Returns:\n",
    "      cluster_df -> df with a value columns and a column corresponding to its cluster\n",
    "    '''\n",
    "\n",
    "    # Initialize the cluster total (t) as 1\n",
    "    t = 1\n",
    "    # initialize cluster dictionary that will hold the samples in each cluster\n",
    "    clusters = dict(zip(range(m), [[] for i in range(m)]))\n",
    "    # initialize the first sample, X_i as the first cluster, C_1\n",
    "    clusters[0].append(data.loc[0, :].to_numpy())\n",
    "    print(\"initialize a new cluster: cluster 0 \")\n",
    "    # For all samples (X_2 ... X_n) find the min distance to each cluster d_min(X_i, C_j)\n",
    "    for row in data.loc[1:, :].to_numpy():\n",
    "        c = 0\n",
    "        curr_clusters = t\n",
    "        # init distance dict for this sample\n",
    "        distance = dict(zip(range(curr_clusters), [\n",
    "                        [] for i in range(curr_clusters)]))\n",
    "        # loop through current clusters computing the distance to each and appending to the distance dict\n",
    "        for c in range(curr_clusters):\n",
    "            distance[c].append(clust_distance(row, clusters[c]))\n",
    "            #distance[c].append(abs(row-np.mean(clusters[c])))\n",
    "        # calculate the shortest distance to a cluster\n",
    "        shortest_dist = min(distance.values())\n",
    "        # find the closest cluster  based using shortest distance\n",
    "        closest_cluster = list(distance.keys())[list(\n",
    "            distance.values()).index(shortest_dist)]\n",
    "        # If the distance is large than alpha and t<m set the sample to the new cluster\n",
    "        if t < m and shortest_dist[0] > alpha:\n",
    "            print('A new cluster has been made: cluster ' + str(c + 1))\n",
    "            clusters[curr_clusters].append(row)\n",
    "            t = t+1\n",
    "        # Else -> add the sample to the clusters dictionary under the key for the closest cluster\n",
    "        else:\n",
    "            clusters[closest_cluster].append(row)\n",
    "    print(\"Clustering complete...\")\n",
    "\n",
    "    # create df from cluster dictionary\n",
    "    cluster_df = pd.DataFrame()\n",
    "    x = 0  # counter for c\n",
    "    for c in clusters:\n",
    "        j = 0  # counter for number of row\n",
    "        for i in clusters[c]:\n",
    "            # append the cluster number the row belongs to at the end of the row \n",
    "            row = pd.DataFrame(np.append(clusters[x][j], x)).T\n",
    "            # df of size (examples, data[0].size + 1)\n",
    "            cluster_df = pd.concat([cluster_df, row], ignore_index=True)\n",
    "            j += 1\n",
    "        x += 1\n",
    "    return cluster_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustering combo #1\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #2\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #3\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #4\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #5\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #6\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #7\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #8\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #9\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #10\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #11\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #12\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #13\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #14\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #15\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #16\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "A new cluster has been made: cluster 3\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #17\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "A new cluster has been made: cluster 3\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #18\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "A new cluster has been made: cluster 3\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #19\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #20\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #21\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #22\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #23\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #24\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #25\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #26\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #27\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #28\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #29\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #30\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #31\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #32\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #33\n",
      "initialize a new cluster: cluster 0 \n",
      "A new cluster has been made: cluster 1\n",
      "A new cluster has been made: cluster 2\n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #34\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #35\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n",
      "\n",
      "Clustering combo #36\n",
      "initialize a new cluster: cluster 0 \n",
      "Clustering complete...\n"
     ]
    }
   ],
   "source": [
    "# sample 20% of data to save clustering computation time\n",
    "# computation time clustering of 100,000 points: 30 min\n",
    "# computation time clustering of 100,000 points: 1 min\n",
    "pca_one_subset = pca_one[::5]\n",
    "pca_two_subset = pca_two[::5]\n",
    "lda_one_subset = lda_one[::5]\n",
    "lda_two_subset = lda_two[::5]\n",
    "\n",
    "projections = [pca_one_subset, pca_two_subset, lda_one_subset, lda_two_subset]\n",
    "\n",
    "\n",
    "m = [2, 3, 4]\n",
    "alpha = [0.4, 0.6, 0.8]\n",
    "\n",
    "k = 1\n",
    "for x in range(len(projections)):\n",
    "    for i in range(len(m)):\n",
    "        for j in range(len(alpha)):\n",
    "            print('\\nClustering combo #{}'.format(k))\n",
    "            df = BSCA(projections[x], m[i], alpha=alpha[i])\n",
    "            df['m'] = m[i]\n",
    "            df['alpha'] = alpha[j]\n",
    "            if x ==0 :\n",
    "                path = 'PCA_1D'\n",
    "            elif x == 1:\n",
    "                path = 'PCA_2D'\n",
    "            elif x == 2:\n",
    "                path = 'LDA_1D'\n",
    "            elif x == 3:\n",
    "                path = 'LDA_2D'\n",
    "            df.to_csv(\"data/bsca/{}/m{}_a{}.csv\".format(path,i,j))\n",
    "            k += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to aid in clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges dfs from a list into one df\n",
    "def merge_dfs(dfs_list):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(dfs_list)):\n",
    "        df = pd.concat([df,dfs_list[i]])\n",
    "    return df\n",
    "\n",
    "# loads csvs as dfs for plotting\n",
    "def load_files(path, file_names, merge=False):\n",
    "    '''\n",
    "    loads the csv files for the given projection specified by the file path and file_names list\n",
    "    returns a list of dfs for that directory\n",
    "    if merge == true then a singular merged dataframe will passed instead of a list of dfs\n",
    "    '''\n",
    "    df_list = []\n",
    "\n",
    "    for i in range(len(file_names)):\n",
    "        temp_df = pd.read_csv(path + file_names[i] + '.csv', index_col=0)\n",
    "        df_list.append(temp_df)\n",
    "    if merge:\n",
    "        return merge_dfs(df_list)\n",
    "    else:\n",
    "        return df_list\n",
    "    \n",
    "\n",
    "def compare_plots(df, pc_num, title):\n",
    "    '''\n",
    "    for plotting all clustering combinations obtained from load_files and merge_dfs\n",
    "    \n",
    "    df = merged df with columns m and alpha\n",
    "    pc_num = num of principle components\n",
    "    title = desired title of fig\n",
    "    '''\n",
    "    #plot for 1D projections\n",
    "    if pc_num == 1:\n",
    "        fig = px.scatter(df, x='0', color='1', facet_row='m', facet_col='alpha',\n",
    "                 labels={\n",
    "                     '0': 'PC1',\n",
    "                     '1': 'Cluster'})\n",
    "        for axis in fig.layout:\n",
    "            if type(fig.layout[axis]) == go.layout.YAxis:\n",
    "                fig.layout[axis].title.text = '' \n",
    "    # plot for 2D projections\n",
    "    elif pc_num == 2:\n",
    "        fig = px.scatter(df, x='0', y='1', color='2', facet_row='m', facet_col='alpha',\n",
    "                 labels={\n",
    "                     '0': 'PC1',\n",
    "                     '1' : 'PC2',\n",
    "                     '2': 'Cluster'})\n",
    "\n",
    "    fig.update_layout(title=title, title_x=0.5, title_y=.98, margin_l=30, margin_b=60)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1D Projections with BSCA <a class=\"anchor\" id=\"1d\"></a>\n",
    "\n",
    "### PCA 1D Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dfs from directory and append to df_list for plotting\n",
    "path = 'data/bsca/PCA_1D/'\n",
    "file_names = ['m0_a0', 'm0_a1', 'm0_a2', 'm1_a0',\n",
    "              'm1_a1', 'm1_a2', 'm2_a0', 'm2_a1', 'm2_a2']\n",
    "\n",
    "pca_1d_clusts = load_files(path=path, file_names=file_names, merge=True)\n",
    "pca_1d_plot = compare_plots(pca_1d_clusts, pc_num=1, title='PCA-1D Clustering')\n",
    "#plotly.offline.plot(pca_1d_plot, filename='figures/bsca/pca_1d_plot.html', auto_open=False)\n",
    "pca_1d_plot.write_image('figures/bsca/pca_1d_plot.png')\n",
    "#pca_1d_plot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two and three unique clusters were found, butfour clusters were not found based on these distance measures. At $m=3$ there seems to be the most equal groupings, but when $m=4$ the 0th cluster seems to take some of the data points from cluster 2. The varying $\\alpha$  did not seem to influence the groupings amongst all $m$ values. \n",
    "\n",
    "![pca1d](figures/bsca/pca_1d_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA 1D Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/bsca/LDA_1D/'\n",
    "lda_1d_clusts = load_files(path=path, file_names=file_names, merge=True)\n",
    "lda_1d_plot = compare_plots(lda_1d_clusts, pc_num=1, title='LDA-1D Clustering')\n",
    "#plotly.offline.plot(lda_1d_plot, filename='figures/bsca/lda_1d_plot.html', auto_open=False)\n",
    "lda_1d_plot.write_image('figures/bsca/lda_1d_plot.png')\n",
    "#lda_1d_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering only found 2 clusters when $m=2$. The other $m$ values failed to find any additional clusters to the 0th cluster. The $\\alpha$ thresholds again did not seem to result in any variation within the clusterings. \n",
    "\n",
    "![lda1d](figures/bsca/lda_1d_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Projections with BSCA <a class=\"anchor\" id=\"2d\"></a>\n",
    "\n",
    "### PCA 2D Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/bsca/PCA_2D/'\n",
    "pca_2d_clusts = load_files(path=path, file_names=file_names, merge=True)\n",
    "pca_2d_plot = compare_plots(pca_2d_clusts, pc_num=2, title='PCA-2D Clustering')\n",
    "#plotly.offline.plot(pca_2d_plot, filename='figures/bsca/pca_2d_plot.html', auto_open=False)\n",
    "pca_2d_plot.write_image('figures/bsca/pca_2d_plot.png')\n",
    "#pca_2d_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA 2D results seemed to show better group separation in comparison with the PCA 1D projection clusters. All considered grouping numbers were succesfully located unlike in the 1D clusterings. The group separation seems to have the most defined boundries at $m=4$. Again the $\\alpha$ thresholds did not seem to affect clustering like the clusterings with both 1D projections. \n",
    "\n",
    "![pca2d](figures/bsca/pca_2d_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA 2D Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/bsca/LDA_2D/'\n",
    "lda_2d_clusts = load_files(path=path, file_names=file_names, merge=True)\n",
    "lda_2d_plot = compare_plots(lda_2d_clusts, pc_num=2, title='LDA-2D Clustering')\n",
    "#plotly.offline.plot(lda_2d_plot, filename='figures/bsca/lda_2d_plot.html', auto_open=False)\n",
    "lda_2d_plot.write_image('figures/bsca/lda_2d_plot.png')\n",
    "#lda_2d_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA 2D projection succesfully found 2 and 3 clusters at $m=2$ and $m=3$. The algorithm failed to detect more than one cluster at $m=4$. Again the $\\alpha$ values did not seem to showing any variation within each $m$ value\n",
    "\n",
    "![lda2d](figures/bsca/lda_2d_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Analysis <a class=\"anchor\" id=\"analysis\"></a>\n",
    "\n",
    "The clustering of the stellar dataset with the BSCA found best clustering results with the 2D projections and within the 2D projections the clustering of the PCA 2D data seems to have resulted in the most defined boundries and found all varying cluster numbers. One potential reason for the poor performance on some projections in comparison with others could be from the considred $\\alpha$ values. Smaller values of $\\alpha$ could help detect more groupings and could aid in the clustering of the LDA projections. Also the reduction of the dataset to a 20% representation in order to save computation time could also be a cause of the poor performace within some projections. The simnplistic nature of this algorithm could also be a pitfall causing poor performance. The BSCA on looks at each data point once, which can lead to intermixing of clustering like found in the PCA2D clsutering when $m=3$. The clusters created by reading the data in the same order each time which could have also affected the performance. The clustering could have resulted in different groupings by initializing the first cluster randomly each time. The BSCA algorithm is a simple clustering method that has a lot of room for imporvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code <a class=\"anchor\" id=\"code2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for calculating the distance from a point (row) to the passed cluster\n",
    "def clust_distance(X, cluster):\n",
    "    # 1D projection, distance calc\n",
    "    if len(X) == 1: # if there is one column..\n",
    "        distance = abs(X - np.mean(cluster))\n",
    "    # 2D projection\n",
    "    elif len(X) == 2: # 2 columns\n",
    "        cluster_means = np.mean(np.array(cluster), axis=0)\n",
    "        distance = np.sqrt((cluster_means[0] - X[0])**2 + (cluster_means[1] - X[1])**2)\n",
    "    else:\n",
    "        print(\"could not find distance to cluster\")\n",
    "\n",
    "    return distance\n",
    "\n",
    "# Clustering algo\n",
    "def BSCA(data, m, alpha):\n",
    "    '''\n",
    "    Arguments: \n",
    "    data -> df of data to cluster, observations row wise\n",
    "    -> int, number of clusters to find within data\n",
    "      alpha -> int, distance threshold, \n",
    "            determines how far away a point can be before it must create a new cluster\n",
    "    Returns:\n",
    "      cluster_df -> df with a value columns and a column corresponding to its cluster\n",
    "    '''\n",
    "\n",
    "    # Initialize the cluster total (t) as 1\n",
    "    t = 1\n",
    "    # initialize cluster dictionary that will hold the samples in each cluster\n",
    "    clusters = dict(zip(range(m), [[] for i in range(m)]))\n",
    "    # initialize the first sample, X_i as the first cluster, C_1\n",
    "    clusters[0].append(data.loc[0, :].to_numpy())\n",
    "    print(\"initialize a new cluster: cluster 0 \")\n",
    "    # For all samples (X_2 ... X_n) find the min distance to each cluster d_min(X_i, C_j)\n",
    "    for row in data.loc[1:, :].to_numpy():\n",
    "        c = 0\n",
    "        curr_clusters = t\n",
    "        # init distance dict for this sample\n",
    "        distance = dict(zip(range(curr_clusters), [\n",
    "                        [] for i in range(curr_clusters)]))\n",
    "        # loop through current clusters computing the distance to each and appending to the distance dict\n",
    "        for c in range(curr_clusters):\n",
    "            distance[c].append(clust_distance(row, clusters[c]))\n",
    "            #distance[c].append(abs(row-np.mean(clusters[c])))\n",
    "        # calculate the shortest distance to a cluster\n",
    "        shortest_dist = min(distance.values())\n",
    "        # find the closest cluster  based using shortest distance\n",
    "        closest_cluster = list(distance.keys())[list(\n",
    "            distance.values()).index(shortest_dist)]\n",
    "        # If the distance is large than alpha and t<m set the sample to the new cluster\n",
    "        if t < m and shortest_dist[0] > alpha:\n",
    "            print('A new cluster has been made: cluster ' + str(c + 1))\n",
    "            clusters[curr_clusters].append(row)\n",
    "            t = t+1\n",
    "        # Else -> add the sample to the clusters dictionary under the key for the closest cluster\n",
    "        else:\n",
    "            clusters[closest_cluster].append(row)\n",
    "    print(\"Clustering complete...\")\n",
    "\n",
    "    # create df from cluster dictionary\n",
    "    cluster_df = pd.DataFrame()\n",
    "    x = 0  # counter for c\n",
    "    for c in clusters:\n",
    "        j = 0  # counter for number of row\n",
    "        for i in clusters[c]:\n",
    "            # append the cluster number the row belongs to at the end of the row \n",
    "            row = pd.DataFrame(np.append(clusters[x][j], x)).T\n",
    "            # df of size (examples, data[0].size + 1)\n",
    "            cluster_df = pd.concat([cluster_df, row], ignore_index=True)\n",
    "            j += 1\n",
    "        x += 1\n",
    "    return cluster_df\n",
    "\n",
    "# concats the dataframes of a directory into one df for plotting all combinations\n",
    "# called within load_files of merge =True\n",
    "def merge_dfs(dfs_list):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(dfs_list)):\n",
    "        df = pd.concat([df,dfs_list[i]])\n",
    "    return df\n",
    "\n",
    "# loads csvs as dfs for plotting\n",
    "def load_files(path, file_names, merge=False):\n",
    "    '''\n",
    "    loads the csv files for the given projection specified by the file path and file_names list\n",
    "    returns a list of dfs for that directory\n",
    "    if merge == true then a singular merged dataframe will passed instead of a list of dfs\n",
    "    '''\n",
    "    df_list = []\n",
    "\n",
    "    for i in range(len(file_names)):\n",
    "        temp_df = pd.read_csv(path + file_names[i] + '.csv', index_col=0)\n",
    "        df_list.append(temp_df)\n",
    "    if merge:\n",
    "        return merge_dfs(df_list)\n",
    "    else:\n",
    "        return df_list\n",
    "\n",
    "# plots all clustering combinations based on m and alpha\n",
    "def compare_plots(df, pc_num, title):\n",
    "    '''\n",
    "    df = merged df with columns m and alpha\n",
    "    pc_num = num of principle components\n",
    "    title = desired title of fig\n",
    "    '''\n",
    "    #plot for 1D projections\n",
    "    if pc_num == 1:\n",
    "        fig = px.scatter(df, x='0', color='1', facet_row='m', facet_col='alpha',\n",
    "                 labels={\n",
    "                     '0': 'PC1',\n",
    "                     '1': 'Cluster'})\n",
    "        for axis in fig.layout:\n",
    "            if type(fig.layout[axis]) == go.layout.YAxis:\n",
    "                fig.layout[axis].title.text = '' \n",
    "    # plot for 2D projections\n",
    "    elif pc_num == 2:\n",
    "        fig = px.scatter(df, x='0', y='1', color='2', facet_row='m', facet_col='alpha',\n",
    "                 labels={\n",
    "                     '0': 'PC1',\n",
    "                     '1' : 'PC2',\n",
    "                     '2': 'Cluster'})\n",
    "\n",
    "    fig.update_layout(title=title, title_x=0.5, title_y=.98, margin_l=30, margin_b=60)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](pca_1d_2.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "935f013ec3274d983f6cf9c6c8d3a038a9827a62579d2563240b276044aef7b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
