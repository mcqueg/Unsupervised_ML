{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with the Fuzzy C-means Algorithm\n",
    "\n",
    "#### Garrett McCue\n",
    "\n",
    "The goal of this assignment is to apply the fuzzy c-means clustering algorithm to the dataset used for [VAT/iVAT analysis](https://nbviewer.org/github/mcqueg/Unsupervised_ML/blob/main/VAT.ipynb) and compare the results from the clustering with the resutls from VAT/iVAT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy C-means\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*O5Ynz1UI6ClCs-Bdf-MG9A.png)\n",
    "\n",
    "Fuzzy C-means clustering is a form of clustering that is referred to as \"soft clustering\". Soft clustering allows for data points to belong to more than one cluster based on their likely hood of similiarity which is defined by a distance measure. For example a data point could have a chance of belonging to cluster A [A = 0.25] and a chance of belonging to cluster B [B = 0.75], and which cluster it would belong to would be decided by a similarity threshold. If the similarity threshold was set at 0.7, then this data point would be grouped within cluster B. This algorithm works by assigning membership values to each observation for all potential clusters. Membership values are based on the distance of the observation to the centroid of a cluster, which means the closer a data point is to the centroid the greater its membership value is for that cluster. The summation of membership values for all clusters pertaining to a singluar observation should eqaul 1. The goal of the algorithm is to minimize its objective function, which can be described as the weighted summation between data points and the clusters. By optimizing the clustering through the minimization of the objective function, the algorithm is grouping points together that are closest to the respective centroid. The clustering algorithm iterates over all data points updating the membership matrix and cluster centroids after each iteration.\n",
    "\n",
    "## FCM Algorithm\n",
    "\n",
    "$ X = \\{x_1, x_2, ... , x_n\\} $ : the set of data points  \n",
    "$ V = \\{v_1, v_2, ... , v_c\\}$ : set of cluster centers\n",
    "\n",
    "$N$ : number of data points  \n",
    "$q$ : fuzziness  \n",
    "$c$ : number of cluster centers\n",
    "$d_{ij}$ : Euclidean distance between $i^\\text{th}$ data point and $j^\\text{th}$ cluster center  \n",
    "$\\mu_{ij}$ : the membership of the $i^\\text{th}$ data point to the $j^\\text{th}$ cluster center  \n",
    "$\\cup$ : membership matrix of all $\\mu_{ij}$ membership values with shape\n",
    "$v_{j}$ : the $j^\\text{th}$ cluster center  \n",
    "$\\beta$ : termination criterion\n",
    "\n",
    "Goal is to minimize:\n",
    "\n",
    "$$J(\\cup,V) = \\sum_{i=1}^{n}\\sum_{j=1}^{c}\\mu_{ij}^{q}d(\\vec{x_i} , \\vec{v_j}) $$\n",
    "where, $$d(\\vec{x_i} , \\vec{v_j}) \\text{is the Euclidean distance between the }i^\\text{th}\\text{ data point to the } j^\\text{th}\\text{ cluster center.} $$\n",
    "\n",
    "1.  Randomly select $v_j$, cluster centers\n",
    "\n",
    "2.  Generate $\\cup$, the fuzzy member matrix, by calculating $\\mu_{ij}$ for $N$\n",
    "\n",
    "    $$\n",
    "    \\mu_{ij}=\\frac{1}{\\displaystyle\\sum_{k=1}^c\\left(\\frac{d(\\vec{x_i} ,\\vec{v_j})}{d(\\vec{x_i} , \\vec{v_j})\n",
    "    }\\right)^{\\frac{2}{q - 1}}}, \\;\\forall\\: i=1,2,...N \\; \\text{and} \\; j=1,2,...,c\n",
    "    $$\n",
    "\n",
    "3.  Compute new $v_j$, cluster centers, based on $\\cup$\n",
    "    $$v_j = \\frac{\\sum_{j=1}^N \\mu_{ij}^q x_i}{\\sum_{j=1}^N\\mu_{ij}^{q}}, \\; \\forall\\: j = 1,2,...,c$$\n",
    "\n",
    "4.  Repeat steps (2) and (3) until $J < \\beta$, or until a set number of max iterations is met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fcmeans import FCM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "hap_df = pd.read_csv(\"data/world_happiness_rankings_2022.csv\")\n",
    "ranking_df = hap_df[['RANK', 'Country']]\n",
    "metrics_df = hap_df.drop(['RANK', 'Country'], axis=1)\n",
    "\n",
    "hap_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "metrics_df = StandardScaler().fit_transform(metrics_df)\n",
    "\n",
    "# apply 2D PCA to data\n",
    "pca_2 = PCA(n_components=2)\n",
    "pca_2_data = pca_2.fit_transform(metrics_df)\n",
    "pca_2_df = pd.DataFrame(data=pca_2_data, columns=['PC1', 'PC2'])\n",
    "pca_2_ranking_df = pd.concat([ranking_df, pca_2_df], axis=1)\n",
    "\n",
    "# apply 3D PCA to data\n",
    "pca_3 = PCA(n_components=3)\n",
    "pca_3_data = pca_3.fit_transform(metrics_df)\n",
    "pca_3_df = pd.DataFrame(data=pca_3_data, columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_3_ranking_df = pd.concat([ranking_df, pca_3_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying FCM\n",
    "\n",
    "When applying FCM we can specify the number of clusters (c) to use and the fuzziness (q) inclusion threshold.\n",
    "Based on the cluster tendency of the dataset using VAT/iVAT, it appears that there could potentially be 3 to 5 clusters.\n",
    "\n",
    "specified parameters to use:\n",
    "\n",
    "- C = [3, 4, 5]\n",
    "- q = [2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: FCM\n",
    "# 3vals for C & q\n",
    "# 10-12 results\n",
    "\n",
    "c = [3, 4, 5]\n",
    "q = [2, 3, 4]\n",
    "\n",
    "X_pca2 = pca_2_df.to_numpy()\n",
    "fcm_2d_3c_2q = FCM(n_clusters=3, m=2.5)\n",
    "fcm_2d_3c_2q.fit(X_pca2)\n",
    "\n",
    "cens_2d_3c_2q = fcm_2d_3c_2q.centers\n",
    "labels_2d_3c_2q = fcm_2d_3c_2q.predict(X_pca2)\n",
    "\n",
    "# plot result\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X_pca2[:, 0], y=X_pca2[:, 1],\n",
    "               mode='markers', marker=dict(color=labels_2d_3c_2q))\n",
    ")\n",
    "# , size=.5)\n",
    "# axes[1].scatter(cens_2d_3c_15q[:,0], cens_2d_3c_15q[:,1], marker=\"x\", s=100, c='red')\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=cens_2d_3c_2q[:, 0], y=cens_2d_3c_2q[:, 1], mode='markers',\n",
    "               marker_color='rgb(0,0,0)', marker_size=20, marker_symbol='x')\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_fcm()\n",
    "# input -> data, c_list, q_list, title\n",
    "\n",
    "# initialize figure with subplots of correct size based on input\n",
    "# create specs list and titles for subplots\n",
    "# loop through c_list\n",
    "# loop through q_list\n",
    "# fcm = FCM(n_clusters=c_list[i], m=q_list[j])\n",
    "# fcm.fit(data)\n",
    "# centers = fcm.centers\n",
    "# labels = fcm.predict(data)\n",
    "# fig_temp = make_subplots(specs=[[{'secondary_y': True}]]))\n",
    "# fig_temp.add_trace(go.Scatter)\n",
    "# fig_temp.add_trace(go.Scatter)\n",
    "# fig.add_trace(fig_temp)\n",
    "\n",
    "\n",
    "# return -> fig with all combinations (9 scatters)\n",
    "\n",
    "\n",
    "c=3\n",
    "r=2\n",
    "specs={'secondary_y': True}\n",
    "specs_c = [specs for x in range(c)]\n",
    "fig_test = make_subplots(specs=[specs_c for x in range(r)], rows=2, cols=3)\n",
    "\n",
    "fig_test.add_trace(\n",
    "    go.Scatter(x=X_pca2[:, 0], y=X_pca2[:, 1], mode='markers', marker=dict(color=labels_2d_3c_2q)),\n",
    "               row=1, col=1\n",
    ")\n",
    "\n",
    "fig_test.add_trace(\n",
    "    go.Scatter(x=cens_2d_3c_2q[:, 0], y=cens_2d_3c_2q[:, 1], mode='markers',\n",
    "               marker_color='rgb(20,170,73)', marker_size=10, marker_symbol='x'),\n",
    "               row=1, col=1\n",
    ")\n",
    "fig_test.update_layout(showlegend=False)\n",
    "\n",
    "fig_test.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCM Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: plot function for all combinations of C & q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Analysis and comparison with VAT/iVAT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Fuzzy C-Means Clustering with Python](https://towardsdatascience.com/fuzzy-c-means-clustering-with-python-f4908c714081)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "935f013ec3274d983f6cf9c6c8d3a038a9827a62579d2563240b276044aef7b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
